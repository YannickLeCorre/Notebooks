---
title: "Resume_analysis"
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
  word_document: default
---

```{R, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(readtext) # to read word documents
library(tidytext) # text mining (check the book https://www.tidytextmining.com/sentiment.html)
library(wordcloud) # draw a word cloud diagram
library(ggplot2)
```

```{R}
#CV <- "2019_last.docx"
#LANGUE <- "en"
CV <- "Ã©bauche_v5.docx"
LANGUE <- "fr"
FILENAME <- paste(getwd(), "/", CV, sep="")
```

```{R, echo=FALSE}
text_df <- readtext(FILENAME)
```

```{R, echo=FALSE}
text_mining_df <- text_df %>%
  unnest_tokens(word, text)
```

```{R, echo=FALSE}
#data(stop_words)
stop_words <- get_stopwords(language = LANGUE)

tidy_text_mining_df <- text_mining_df %>%
  anti_join(stop_words)
```

```{R, echo=FALSE}
tidy_text_mining_df %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

Filtre des occurences > $`r N <- 3; N`$

```{R, echo=FALSE}
tidy_text_mining_df %>%
  count(word, sort = TRUE) %>%
  filter(n > N) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```